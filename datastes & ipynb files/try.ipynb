{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d340e5",
   "metadata": {},
   "source": [
    "# Reading Data (MileStone - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f84173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b790d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"amazonLabelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07971f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa681eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 3 columns):\n",
      "S            999 non-null int64\n",
      "Feedback     999 non-null object\n",
      "Sentiment    999 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 23.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31fc3a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>288.530761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>250.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>749.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                S\n",
       "count  999.000000\n",
       "mean   500.000000\n",
       "std    288.530761\n",
       "min      1.000000\n",
       "25%    250.500000\n",
       "50%    500.000000\n",
       "75%    749.500000\n",
       "max    999.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa1a1e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S                                           Feedback Sentiment\n",
       "0  1                        Good case, Excellent value.  Positive\n",
       "1  2                             Great for the jawbone.  Positive\n",
       "2  3  Tied to charger for conversations lasting more...  Negative\n",
       "3  4                                  The mic is great.  Positive\n",
       "4  5  I have to jiggle the plug to get it to line up...  Negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a52916f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>994</td>\n",
       "      <td>995</td>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>996</td>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>997</td>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>998</td>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>999</td>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       S                                           Feedback Sentiment\n",
       "994  995  The screen does get smudged easily because it ...  Negative\n",
       "995  996  What a piece of junk.. I lose more calls on th...  Negative\n",
       "996  997                       Item Does Not Match Picture.  Negative\n",
       "997  998  The only thing that disappoint me is the infra...  Negative\n",
       "998  999  You can not answer calls with the unit, never ...  Negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b0219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4057fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(x):\n",
    "    ans=0\n",
    "    for sen in x:\n",
    "        if (sen=='Positive'):\n",
    "            ans=ans+1\n",
    "    return ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd0b560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "Positive = find(df[\"Sentiment\"])\n",
    "print(Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf0de927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n"
     ]
    }
   ],
   "source": [
    "Negative = len(df.Sentiment)-Positive\n",
    "print(Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "808d4e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "Sentiment = ['Negative', 'Positive']\n",
    "data = [Negative, Positive]\n",
    "ax.bar(Sentiment, data)\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Data')\n",
    "plt.title(\" Sentiment Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b74c22",
   "metadata": {},
   "source": [
    "# Milestone - 2\n",
    "# Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f570957",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "def remove_puc(text):\n",
    "    for ele in text:\n",
    "        if ele in punc:\n",
    "            text = text.replace(ele, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9c2b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"punctuation_removed\"] = df[\"Feedback\"].apply(lambda x: remove_puc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfabe6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good case Excellent value'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.punctuation_removed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a6ae2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>punctuation_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good case Excellent value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Great for the jawbone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>The mic is great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S                                           Feedback Sentiment  \\\n",
       "0  1                        Good case, Excellent value.  Positive   \n",
       "1  2                             Great for the jawbone.  Positive   \n",
       "2  3  Tied to charger for conversations lasting more...  Negative   \n",
       "3  4                                  The mic is great.  Positive   \n",
       "4  5  I have to jiggle the plug to get it to line up...  Negative   \n",
       "\n",
       "                                 punctuation_removed  \n",
       "0                          Good case Excellent value  \n",
       "1                              Great for the jawbone  \n",
       "2  Tied to charger for conversations lasting more...  \n",
       "3                                   The mic is great  \n",
       "4  I have to jiggle the plug to get it to line up...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953cea9",
   "metadata": {},
   "source": [
    "# Tokenization using NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24cea117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cd41a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'case', 'excellent', 'value']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "df[\"nltk_token\"] = df[\"punctuation_removed\"].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "df.nltk_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ca91aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>punctuation_removed</th>\n",
       "      <th>nltk_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good case Excellent value</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Great for the jawbone</td>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>The mic is great</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S                                           Feedback Sentiment  \\\n",
       "0  1                        Good case, Excellent value.  Positive   \n",
       "1  2                             Great for the jawbone.  Positive   \n",
       "2  3  Tied to charger for conversations lasting more...  Negative   \n",
       "3  4                                  The mic is great.  Positive   \n",
       "4  5  I have to jiggle the plug to get it to line up...  Negative   \n",
       "\n",
       "                                 punctuation_removed  \\\n",
       "0                          Good case Excellent value   \n",
       "1                              Great for the jawbone   \n",
       "2  Tied to charger for conversations lasting more...   \n",
       "3                                   The mic is great   \n",
       "4  I have to jiggle the plug to get it to line up...   \n",
       "\n",
       "                                          nltk_token  \n",
       "0                     [good, case, excellent, value]  \n",
       "1                         [great, for, the, jawbone]  \n",
       "2  [tied, to, charger, for, conversations, lastin...  \n",
       "3                              [the, mic, is, great]  \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f08f4",
   "metadata": {},
   "source": [
    "# Removing Stop_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a480d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"StopWords_Removed\"] = df['nltk_token'].apply(lambda x: [item for item in x if item not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed5246c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>punctuation_removed</th>\n",
       "      <th>nltk_token</th>\n",
       "      <th>StopWords_Removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good case Excellent value</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Great for the jawbone</td>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>[tied, charger, conversations, lasting, 45, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>The mic is great</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>[mic, great]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "      <td>[jiggle, plug, get, line, right, get, decent, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S                                           Feedback Sentiment  \\\n",
       "0  1                        Good case, Excellent value.  Positive   \n",
       "1  2                             Great for the jawbone.  Positive   \n",
       "2  3  Tied to charger for conversations lasting more...  Negative   \n",
       "3  4                                  The mic is great.  Positive   \n",
       "4  5  I have to jiggle the plug to get it to line up...  Negative   \n",
       "\n",
       "                                 punctuation_removed  \\\n",
       "0                          Good case Excellent value   \n",
       "1                              Great for the jawbone   \n",
       "2  Tied to charger for conversations lasting more...   \n",
       "3                                   The mic is great   \n",
       "4  I have to jiggle the plug to get it to line up...   \n",
       "\n",
       "                                          nltk_token  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                         [great, for, the, jawbone]   \n",
       "2  [tied, to, charger, for, conversations, lastin...   \n",
       "3                              [the, mic, is, great]   \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...   \n",
       "\n",
       "                                   StopWords_Removed  \n",
       "0                     [good, case, excellent, value]  \n",
       "1                                   [great, jawbone]  \n",
       "2  [tied, charger, conversations, lasting, 45, mi...  \n",
       "3                                       [mic, great]  \n",
       "4  [jiggle, plug, get, line, right, get, decent, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db64db6",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79b6c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import xgboost, textblob, string\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4144be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Negative', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30dd74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['punctuation_removed'], df['Sentiment'])\n",
    "# label encode the target variable\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d8430b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df['punctuation_removed'])\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count = count_vect.transform(train_x)\n",
    "xvalid_count = count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f7a5e",
   "metadata": {},
   "source": [
    "# Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d2155ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}',max_features=5000)\n",
    "tfidf_vect.fit(df['punctuation_removed'])\n",
    "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf = tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a48fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}',ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(df['punctuation_removed'])\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram = tfidf_vect_ngram.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75d7fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char',token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(df['punctuation_removed'])\n",
    "xtrain_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(train_x)\n",
    "xvalid_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "076ca068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, vector_train, label, vector_valid):\n",
    "    classifier.fit(vector_train, label)\n",
    "    predictions = classifier.predict(vector_valid)\n",
    "    return classification_report(predictions, valid_y ,target_names=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17837d44",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f85d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.85      0.79       115\n",
      "    Positive       0.85      0.74      0.79       135\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.80      0.80      0.79       250\n",
      "weighted avg       0.80      0.79      0.79       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y,xvalid_count)\n",
    "print (\"NB, Count Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a62761d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, WordLevel TF-IDF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.86      0.80       116\n",
      "    Positive       0.86      0.75      0.80       134\n",
      "\n",
      "    accuracy                           0.80       250\n",
      "   macro avg       0.81      0.81      0.80       250\n",
      "weighted avg       0.81      0.80      0.80       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y,xvalid_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9adeba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, N-Gram Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.61      0.84      0.70        97\n",
      "    Positive       0.86      0.66      0.75       153\n",
      "\n",
      "    accuracy                           0.73       250\n",
      "   macro avg       0.74      0.75      0.73       250\n",
      "weighted avg       0.76      0.73      0.73       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y,xvalid_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdbff37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, CharLevel Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.80      0.76       121\n",
      "    Positive       0.79      0.72      0.76       129\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.76      0.76      0.76       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars,train_y, xvalid_tfidf_ngram_chars)\n",
    "print (\"NB, CharLevel Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b9ecb",
   "metadata": {},
   "source": [
    "# Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96c6c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.82      0.83       137\n",
      "    Positive       0.79      0.81      0.80       113\n",
      "\n",
      "    accuracy                           0.82       250\n",
      "   macro avg       0.81      0.82      0.81       250\n",
      "weighted avg       0.82      0.82      0.82       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y,xvalid_count)\n",
    "print( \"LR, Count Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5082912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, WordLevel TF-IDF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.82      0.83       137\n",
      "    Positive       0.79      0.81      0.80       113\n",
      "\n",
      "    accuracy                           0.82       250\n",
      "   macro avg       0.81      0.82      0.81       250\n",
      "weighted avg       0.82      0.82      0.82       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y,xvalid_tfidf)\n",
    "print( \"LR, WordLevel TF-IDF: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba928d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, N-Gram Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.74      0.77       143\n",
      "    Positive       0.68      0.75      0.71       107\n",
      "\n",
      "    accuracy                           0.74       250\n",
      "   macro avg       0.74      0.74      0.74       250\n",
      "weighted avg       0.75      0.74      0.75       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram,train_y, xvalid_tfidf_ngram)\n",
    "print( \"LR, N-Gram Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05ad4d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, CharLevel Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.77      0.77      0.77       133\n",
      "    Positive       0.74      0.74      0.74       117\n",
      "\n",
      "    accuracy                           0.75       250\n",
      "   macro avg       0.75      0.75      0.75       250\n",
      "weighted avg       0.75      0.75      0.75       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(),xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print( \"LR, CharLevel Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6072415b",
   "metadata": {},
   "source": [
    "# Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b31d5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Count Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         0\n",
      "    Positive       1.00      0.47      0.64       250\n",
      "\n",
      "    accuracy                           0.47       250\n",
      "   macro avg       0.50      0.23      0.32       250\n",
      "weighted avg       1.00      0.47      0.64       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SVM on Count Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_count, train_y, xvalid_count)\n",
    "print( \"SVM, Count Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee2c7452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, WordLevel TF-IDF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         0\n",
      "    Positive       1.00      0.47      0.64       250\n",
      "\n",
      "    accuracy                           0.47       250\n",
      "   macro avg       0.50      0.23      0.32       250\n",
      "weighted avg       1.00      0.47      0.64       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SVM on Word Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print( \"SVM, WordLevel TF-IDF: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae09a590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         0\n",
      "    Positive       1.00      0.47      0.64       250\n",
      "\n",
      "    accuracy                           0.47       250\n",
      "   macro avg       0.50      0.23      0.32       250\n",
      "weighted avg       1.00      0.47      0.64       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y,xvalid_tfidf_ngram)\n",
    "print( \"SVM, N-Gram Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c878b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, CharLevel Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         0\n",
      "    Positive       1.00      0.47      0.64       250\n",
      "\n",
      "    accuracy                           0.47       250\n",
      "   macro avg       0.50      0.23      0.32       250\n",
      "weighted avg       1.00      0.47      0.64       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SVM on Character Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram_chars, train_y,xvalid_tfidf_ngram_chars)\n",
    "print( \"SVM, CharLevel Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496db1aa",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec842270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.78      0.80       141\n",
      "    Positive       0.74      0.79      0.76       109\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.78      0.78      0.78       250\n",
      "weighted avg       0.79      0.78      0.78       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# RF on Count Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y,xvalid_count)\n",
    "print( \"RF, Count Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c5d7617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, WordLevel TF-IDF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.71      0.78       162\n",
      "    Positive       0.60      0.80      0.68        88\n",
      "\n",
      "    accuracy                           0.74       250\n",
      "   macro avg       0.73      0.75      0.73       250\n",
      "weighted avg       0.77      0.74      0.75       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y,xvalid_tfidf)\n",
    "print( \"RF, WordLevel TF-IDF: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73072d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, N-Gram Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.70      0.75       152\n",
      "    Positive       0.62      0.73      0.67        98\n",
      "\n",
      "    accuracy                           0.72       250\n",
      "   macro avg       0.71      0.72      0.71       250\n",
      "weighted avg       0.73      0.72      0.72       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# RF on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram,train_y, xvalid_tfidf_ngram)\n",
    "print( \"RF, N-Gram Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "767b5178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, CharLevel Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.73      0.77       149\n",
      "    Positive       0.66      0.76      0.71       101\n",
      "\n",
      "    accuracy                           0.74       250\n",
      "   macro avg       0.74      0.75      0.74       250\n",
      "weighted avg       0.75      0.74      0.75       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# RF on Character Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(),xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print( \"RF, CharLevel Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b584c2",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a52b0ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, Count Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.76      0.80       147\n",
      "    Positive       0.70      0.80      0.75       103\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.77      0.78      0.77       250\n",
      "weighted avg       0.78      0.78      0.78       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting on Count Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y,xvalid_count.tocsc())\n",
    "print (\"Xgb, Count Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4b69ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, WordLevel TF-IDF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.77      0.76       129\n",
      "    Positive       0.74      0.72      0.73       121\n",
      "\n",
      "    accuracy                           0.74       250\n",
      "   macro avg       0.74      0.74      0.74       250\n",
      "weighted avg       0.74      0.74      0.74       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y,xvalid_tfidf.tocsc())\n",
    "print (\"Xgb, WordLevel TF-IDF: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9aef9dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, N-Gram Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.63      0.72       179\n",
      "    Positive       0.43      0.70      0.53        71\n",
      "\n",
      "    accuracy                           0.65       250\n",
      "   macro avg       0.63      0.66      0.62       250\n",
      "weighted avg       0.72      0.65      0.67       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram.tocsc(),train_y, xvalid_tfidf_ngram)\n",
    "print( \"Xgb, N-Gram Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22a272f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, CharLevel Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.76      0.78       140\n",
      "    Positive       0.71      0.75      0.73       110\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.75      0.76      0.75       250\n",
      "weighted avg       0.76      0.76      0.76       250\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "print (\"Xgb, CharLevel Vectors: \\n\", accuracy)\n",
    "print(\"------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81b5d625eb843f70cb0a63f7b1e49de4a69249bc87335ed39b4e241e37e91142"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
